{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big Data Internship.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8mh+JlUwT+On/bmB/BrGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktatarch/Coffee_Machine/blob/master/Big_Data_Internship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Big Data Internship test task (Avenga Academy)**\n",
        "\n",
        "---\n",
        "# Goal:\n",
        "\n",
        "Using [a dataset](https://www.kaggle.com/datasets/anandaramg/taxi-trip-data-nyc?resource=download) and Apache Spark (Scala or Python), get the following report:\n",
        "\n",
        "* **Vendor**: string (nullable = true) - name of vendor\n",
        "* **Payment Type**: string (nullable = true) - name of payment type\n",
        "* **Payment Rate**: double (nullable = true) - payment_total / passengers count per vendor and payment type\n",
        "* **Next Payment Rate**: double (nullable = true) - next record(bigger) payment rate for vendor\n",
        "* **Max Payment Rate**: double (nullable = true) - max payment rate for vendor\n",
        "* **Percents to next rate**: string (nullable = true) - how many points (in percents) is necessary to achieve the next record payment rate"
      ],
      "metadata": {
        "id": "6zK8lcC1tKtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I start with updating our environment and instaling:"
      ],
      "metadata": {
        "id": "9EOBVpiZumG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dIC0bIebyFKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc258604-1f97-4f9b-983f-861ca9bfa0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [902 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,077 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,336 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,528 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,306 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,905 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,064 kB]\n",
            "Fetched 14.4 MB in 4s (3,874 kB/s)\n",
            "Reading package lists... Done\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 46 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 52.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=d8d88fb11aa9714788549bdcec99880e0ac2f03f0342ff931342bacb78547d95\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "fxmiG7IayT8_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "lH2aUJ2syWIo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "spark = SparkSession.builder.getOrCreate() "
      ],
      "metadata": {
        "id": "XCqJ9ZuhyZPY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rmWDB1prQLyI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After everything necessary is installed - I retrieve data from the taxi_tripdata dataset using spark.read (the dataset itself was initially downloaded from [kaddle](https://www.kaggle.com/datasets/anandaramg/taxi-trip-data-nyc?resource=download)) and uploaded to Google Colab folder for further use.\n",
        "\n",
        "As at the moment I'm more familiar with Pandas - I'll convert received spark dataset to Pandas on read. However, I plan to rewrite this project with PySpark as soon as I investigate PySpark a bit more. "
      ],
      "metadata": {
        "id": "tP8F6dShu39y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('taxi_tripdata.csv', header=True, inferSchema=True).toPandas()"
      ],
      "metadata": {
        "id": "L1qzKo780EAK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm copying received dataset specifying columns I would work with, in order to prevent calculations and displaying of the data from unused fields:"
      ],
      "metadata": {
        "id": "eZrXRypBwdTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['VendorID', 'payment_type', 'passenger_count', 'total_amount']].copy()"
      ],
      "metadata": {
        "id": "gU1HlTZlEYj8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've decided to start with getting **Payment Rate** and **Max Payment Rate** column values. \n",
        "\n",
        "**Payment Rate** should be calculated as `payment_total / passengers count` per vendor and payment type. It also can include Null values. \n",
        "\n",
        "As our dataset also includes 0 values for **Passengers Count**, which will cause the **Payment Rate** to be infinity and negatively infulence on our report quality.\n",
        "\n",
        "As by the information provideed at the data source, data for this column is the number of passengers in the vehicle, and is a driver-entered value. So, I decided to replace zero values with Null.\n",
        "\n",
        "After **Payment Rate** values are calculated, I can proceed with adding a new column for storing **Max Payment Rate** values, which should display `max payment rate` for vendor."
      ],
      "metadata": {
        "id": "mRfBe57Qw7ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['passenger_count'] = df['passenger_count'].replace(0, np.nan)\n",
        "df['payment_rate'] = df.total_amount / df.passenger_count\n",
        "\n",
        "df = df.join(df.groupby('VendorID')['payment_rate'].max(), on='VendorID', rsuffix='_max')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-a-n268Pdq-",
        "outputId": "f57c1d82-5029-459d-ccc2-f1f2283e1b1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       VendorID  payment_type  passenger_count  total_amount  payment_rate  \\\n",
            "0           1.0           2.0              1.0          7.30          7.30   \n",
            "1           2.0           2.0              2.0         43.30         21.65   \n",
            "2           2.0           1.0              1.0         10.14         10.14   \n",
            "3           2.0           2.0              1.0          7.80          7.80   \n",
            "4           2.0           2.0              1.0          8.30          8.30   \n",
            "...         ...           ...              ...           ...           ...   \n",
            "83686       NaN           NaN              NaN         59.84           NaN   \n",
            "83687       NaN           NaN              NaN         25.87           NaN   \n",
            "83688       NaN           NaN              NaN         22.75           NaN   \n",
            "83689       NaN           NaN              NaN         54.12           NaN   \n",
            "83690       NaN           NaN              NaN         48.89           NaN   \n",
            "\n",
            "       payment_rate_max  \n",
            "0                184.21  \n",
            "1                480.31  \n",
            "2                480.31  \n",
            "3                480.31  \n",
            "4                480.31  \n",
            "...                 ...  \n",
            "83686               NaN  \n",
            "83687               NaN  \n",
            "83688               NaN  \n",
            "83689               NaN  \n",
            "83690               NaN  \n",
            "\n",
            "[83691 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll be getting **Next Payment Rate** values. It should be represented as next record(bigger) payment rate for vendor. \n",
        "\n",
        "In order to determine next(bigger) payment rates for provider - let's sort and get unique payment rates values per provider `using sort_values` and `groupby`\n",
        "\n",
        "After we get all values per provider, we can shift it by one using `Numpy roll()`\n",
        "It's also important to take care about the last sorted value per each provider, in order to make sure that it's not shifted to the smaller value than it was.\n",
        "\n",
        "In case the maximum payment rate is already achieved - no need to shift this value. There is no Next Payment Rate for it, so we'll replace it with NaN.\n"
      ],
      "metadata": {
        "id": "cYyx5Rcy2GyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique = df.sort_values(['payment_rate']).groupby('VendorID')['payment_rate'].unique()\n",
        "\n",
        "print(f\"Unique Payment Rate values per provider: {unique}\")\n",
        "\n",
        "new = np.roll(unique[1], -1)\n",
        "new[-1] = np.nan\n",
        "\n",
        "new1 = np.roll(unique[2], -1)\n",
        "new1[-1] = np.nan\n",
        "\n",
        "print(f\"Shifted by 1 Payment Rate values per provider: {new}{new1}\")\n",
        "\n",
        "df1 = pd.DataFrame({'VendorID': 1.0, 'payment_rate': unique[1]}) #create a dataset from retrieved values for Vendor 1.0\n",
        "df1['next_payment_rate'] = new\n",
        "\n",
        "df2 = pd.DataFrame({'VendorID': 2.0, 'payment_rate': unique[2]}) #create a dataset from retrieved values for Vendor 2.0\n",
        "df2['next_payment_rate'] = new1\n",
        "\n",
        "combined_df = df1.append(df2) #append datasets in order to merge it with our main dataset later on\n",
        "print(combined_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bZb3aJ4Qu8l",
        "outputId": "037e8952-a0b6-4d48-9122-cd0864de823b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Payment Rate values per provider: VendorID\n",
            "1.0    [0.0, 0.8, 1.075, 1.0999999999999999, 1.45, 1....\n",
            "2.0    [-150.3, -57.3, -30.3, -25.15, -20.3, -18.3, -...\n",
            "Name: payment_rate, dtype: object\n",
            "Shifted by 1 Payment Rate values per provider: [  0.8     1.075   1.1   ... 184.21      nan     nan][-57.3  -30.3  -25.15 ... 480.31    nan    nan]\n",
            "      VendorID  payment_rate  next_payment_rate\n",
            "0          1.0         0.000              0.800\n",
            "1          1.0         0.800              1.075\n",
            "2          1.0         1.075              1.100\n",
            "3          1.0         1.100              1.450\n",
            "4          1.0         1.450              1.600\n",
            "...        ...           ...                ...\n",
            "3450       2.0       207.480            225.000\n",
            "3451       2.0       225.000            443.370\n",
            "3452       2.0       443.370            480.310\n",
            "3453       2.0       480.310                NaN\n",
            "3454       2.0           NaN                NaN\n",
            "\n",
            "[4484 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last value we did not get yet - is the **Percents to next rate**, which should describe how many points (in percents) is necessary to achieve the next record payment rate. \n",
        "\n",
        "We can calculate it as `Next Payment Rate (in persents) - Payment Rate (in persents)` for each data entry, taking the Max Payment Rate per provider as 100%\n",
        "\n",
        "As we have a request of string type for this column - I can assume, that % mark should be added."
      ],
      "metadata": {
        "id": "8L6HdHQt4mcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = df.merge(combined_df, how=\"left\", on=[\"VendorID\",\"payment_rate\"]) #performing left join to get the data merged\n",
        "\n",
        "merged_data['percent'] = ((merged_data.next_payment_rate * 100.00 / merged_data.payment_rate_max) - (merged_data.payment_rate * 100.00 / merged_data.payment_rate_max)) #getting Next Payment Rate values\n",
        "merged_data.loc[merged_data['payment_rate'] == merged_data['payment_rate_max'], 'percent'] = \"0\" #taking care of our max payment rate values, by setting percent to 0%\n",
        "merged_data.loc[merged_data['percent'].notna() == True, 'percent'] = merged_data['percent'].astype(str) + \"%\" #converting column into String, and adding % sign to not NaN values\n",
        "\n",
        "print(merged_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvPmxsjlQ_OT",
        "outputId": "425ce6c1-9ac3-4314-ac24-431a6a072bd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       VendorID  payment_type  passenger_count  total_amount  payment_rate  \\\n",
            "0           1.0           2.0              1.0          7.30          7.30   \n",
            "1           2.0           2.0              2.0         43.30         21.65   \n",
            "2           2.0           1.0              1.0         10.14         10.14   \n",
            "3           2.0           2.0              1.0          7.80          7.80   \n",
            "4           2.0           2.0              1.0          8.30          8.30   \n",
            "...         ...           ...              ...           ...           ...   \n",
            "83686       NaN           NaN              NaN         59.84           NaN   \n",
            "83687       NaN           NaN              NaN         25.87           NaN   \n",
            "83688       NaN           NaN              NaN         22.75           NaN   \n",
            "83689       NaN           NaN              NaN         54.12           NaN   \n",
            "83690       NaN           NaN              NaN         48.89           NaN   \n",
            "\n",
            "       payment_rate_max  next_payment_rate                 percent  \n",
            "0                184.21              7.315   0.008142880408229747%  \n",
            "1                480.31             21.660  0.0020819887156209305%  \n",
            "2                480.31             10.150  0.0020819887156213746%  \n",
            "3                480.31              7.810  0.0020819887156211525%  \n",
            "4                480.31              8.310  0.0020819887156207084%  \n",
            "...                 ...                ...                     ...  \n",
            "83686               NaN                NaN                     NaN  \n",
            "83687               NaN                NaN                     NaN  \n",
            "83688               NaN                NaN                     NaN  \n",
            "83689               NaN                NaN                     NaN  \n",
            "83690               NaN                NaN                     NaN  \n",
            "\n",
            "[83691 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final steps: replacing values from VendorID and payment_type with corresponding names from documentation. Also, renaming all fields and dropping columns don't need in our final report."
      ],
      "metadata": {
        "id": "oiIGW-az7r3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.VendorID.replace([1.0, 2.0], [\"Creative Mobile Technologies, LLC\", \"VeriFone Inc.\"], inplace=True)\n",
        "merged_data.payment_type.replace([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [\"Credit card\", \"Cash\", \"No charge\", \"Dispute\", \"Unknown\", \"Voided trip\"], inplace=True)\n",
        "\n",
        "merged_data.rename(columns = {'VendorID':'Vendor', 'payment_type' : 'Payment Type', 'payment_rate' : 'Payment Rate', 'next_payment_rate' : 'Next Payment Rate', 'payment_rate_max' : 'Max Payment Rate', 'percent': 'Percents to next rate'}, inplace = True)\n",
        "final = merged_data.drop(['passenger_count', 'total_amount'], axis=1)\n",
        "print(merged_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp5BxBz1bU24",
        "outputId": "4045a468-9838-4edc-9b75-d607ae71c5c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Vendor Payment Type  passenger_count  \\\n",
            "0      Creative Mobile Technologies, LLC         Cash              1.0   \n",
            "1                          VeriFone Inc.         Cash              2.0   \n",
            "2                          VeriFone Inc.  Credit card              1.0   \n",
            "3                          VeriFone Inc.         Cash              1.0   \n",
            "4                          VeriFone Inc.         Cash              1.0   \n",
            "...                                  ...          ...              ...   \n",
            "83686                                NaN          NaN              NaN   \n",
            "83687                                NaN          NaN              NaN   \n",
            "83688                                NaN          NaN              NaN   \n",
            "83689                                NaN          NaN              NaN   \n",
            "83690                                NaN          NaN              NaN   \n",
            "\n",
            "       total_amount  Payment Rate  Max Payment Rate  Next Payment Rate  \\\n",
            "0              7.30          7.30            184.21              7.315   \n",
            "1             43.30         21.65            480.31             21.660   \n",
            "2             10.14         10.14            480.31             10.150   \n",
            "3              7.80          7.80            480.31              7.810   \n",
            "4              8.30          8.30            480.31              8.310   \n",
            "...             ...           ...               ...                ...   \n",
            "83686         59.84           NaN               NaN                NaN   \n",
            "83687         25.87           NaN               NaN                NaN   \n",
            "83688         22.75           NaN               NaN                NaN   \n",
            "83689         54.12           NaN               NaN                NaN   \n",
            "83690         48.89           NaN               NaN                NaN   \n",
            "\n",
            "        Percents to next rate  \n",
            "0       0.008142880408229747%  \n",
            "1      0.0020819887156209305%  \n",
            "2      0.0020819887156213746%  \n",
            "3      0.0020819887156211525%  \n",
            "4      0.0020819887156207084%  \n",
            "...                       ...  \n",
            "83686                     NaN  \n",
            "83687                     NaN  \n",
            "83688                     NaN  \n",
            "83689                     NaN  \n",
            "83690                     NaN  \n",
            "\n",
            "[83691 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a custom Schema with prefered column types, and converting Pandas dataframe back into PySpark. "
      ],
      "metadata": {
        "id": "PHZWNUsx8Wx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySchema = StructType([\n",
        "    StructField('Vendor', StringType(), True),\n",
        "    StructField('Payment Type', StringType(), True),\n",
        "    StructField('Payment Rate', DoubleType(), True),\n",
        "    StructField('Next Payment Rate', DoubleType(), True),\n",
        "    StructField('Max Payment Rate', DoubleType(), True),\n",
        "    StructField('Percents to next rate', StringType(), True)\n",
        "    ])\n",
        "\n",
        "taxiReport = spark.createDataFrame(final, schema=mySchema)\n",
        "taxiReport.printSchema()\n",
        "taxiReport.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EtFW3DB3l4",
        "outputId": "fe15b96d-c534-439f-f618-21777dfa991e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Vendor: string (nullable = true)\n",
            " |-- Payment Type: string (nullable = true)\n",
            " |-- Payment Rate: double (nullable = true)\n",
            " |-- Next Payment Rate: double (nullable = true)\n",
            " |-- Max Payment Rate: double (nullable = true)\n",
            " |-- Percents to next rate: string (nullable = true)\n",
            "\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "|              Vendor|Payment Type|Payment Rate|Next Payment Rate| Max Payment Rate|Percents to next rate|\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "|Creative Mobile T...|        Cash|         7.3|           184.21|            7.315| 0.008142880408229...|\n",
            "|       VeriFone Inc.|        Cash|       21.65|           480.31|            21.66| 0.002081988715620...|\n",
            "|       VeriFone Inc.| Credit card|       10.14|           480.31|            10.15| 0.002081988715621...|\n",
            "|       VeriFone Inc.|        Cash|         7.8|           480.31|             7.81| 0.002081988715621...|\n",
            "|       VeriFone Inc.|        Cash|         8.3|           480.31|8.309999999999999| 0.002081988715620...|\n",
            "|Creative Mobile T...| Credit card|       15.05|           184.21|            15.06| 0.005428586938819...|\n",
            "|       VeriFone Inc.|        Cash|        18.8|           480.31|            18.81| 0.002081988715620...|\n",
            "|       VeriFone Inc.|        Cash|         6.3|           480.31|             6.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       10.38|           480.31|             10.4| 0.004163977431242...|\n",
            "|       VeriFone Inc.|        Cash|         8.8|           480.31|            8.805| 0.001040994357810...|\n",
            "|       VeriFone Inc.| Credit card|        15.7|           480.31|            15.72| 0.004163977431242...|\n",
            "|       VeriFone Inc.|        Cash|        13.3|           480.31|            13.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|        57.3|           480.31|            57.35| 0.01040994357810554%|\n",
            "|       VeriFone Inc.|        Cash|       73.35|           480.31|            73.65| 0.06245966146863857%|\n",
            "|       VeriFone Inc.|        Cash|         7.3|           480.31|             7.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|        9.49|           480.31|              9.5| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       49.85|           480.31|            49.92| 0.014573921009349...|\n",
            "|       VeriFone Inc.| Credit card|       38.85|           480.31|            38.88| 0.006245966146865...|\n",
            "|       VeriFone Inc.|        Cash|         7.8|           480.31|             7.81| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       24.96|           480.31|             25.0| 0.00832795486248461%|\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next part of the task - is to save the data as csv file, and send it via email using python/scala function. \n",
        "\n",
        "Be default, spark is deviding csv files on creation to a few parts. I've used `coalesce` in order to get the complete file as one document."
      ],
      "metadata": {
        "id": "xzwe6ZQR9C2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxiReport.coalesce(1).write.format(\"csv\").option(\"header\", \"true\").save(\"reportDataTaxi.csv\") # saving dataframe as csv file\n",
        "\n",
        "# at this step, I'll manually rename the generated csv file under reportTaxiData.csv folder to reportDataTaxi.csv"
      ],
      "metadata": {
        "id": "RQ8KlCcNH1SC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"reportDataTaxi.csv/reportDataTaxi.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L3CZXeWM3bd",
        "outputId": "b2aefca3-3655-45d0-cf70-8c1b8c95834c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Vendor: string (nullable = true)\n",
            " |-- Payment Type: string (nullable = true)\n",
            " |-- Payment Rate: double (nullable = true)\n",
            " |-- Next Payment Rate: double (nullable = true)\n",
            " |-- Max Payment Rate: double (nullable = true)\n",
            " |-- Percents to next rate: string (nullable = true)\n",
            "\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "|              Vendor|Payment Type|Payment Rate|Next Payment Rate| Max Payment Rate|Percents to next rate|\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "|Creative Mobile T...|        Cash|         7.3|           184.21|            7.315| 0.008142880408229...|\n",
            "|       VeriFone Inc.|        Cash|       21.65|           480.31|            21.66| 0.002081988715620...|\n",
            "|       VeriFone Inc.| Credit card|       10.14|           480.31|            10.15| 0.002081988715621...|\n",
            "|       VeriFone Inc.|        Cash|         7.8|           480.31|             7.81| 0.002081988715621...|\n",
            "|       VeriFone Inc.|        Cash|         8.3|           480.31|8.309999999999999| 0.002081988715620...|\n",
            "|Creative Mobile T...| Credit card|       15.05|           184.21|            15.06| 0.005428586938819...|\n",
            "|       VeriFone Inc.|        Cash|        18.8|           480.31|            18.81| 0.002081988715620...|\n",
            "|       VeriFone Inc.|        Cash|         6.3|           480.31|             6.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       10.38|           480.31|             10.4| 0.004163977431242...|\n",
            "|       VeriFone Inc.|        Cash|         8.8|           480.31|            8.805| 0.001040994357810...|\n",
            "|       VeriFone Inc.| Credit card|        15.7|           480.31|            15.72| 0.004163977431242...|\n",
            "|       VeriFone Inc.|        Cash|        13.3|           480.31|            13.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|        57.3|           480.31|            57.35| 0.01040994357810554%|\n",
            "|       VeriFone Inc.|        Cash|       73.35|           480.31|            73.65| 0.06245966146863857%|\n",
            "|       VeriFone Inc.|        Cash|         7.3|           480.31|             7.31| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|        9.49|           480.31|              9.5| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       49.85|           480.31|            49.92| 0.014573921009349...|\n",
            "|       VeriFone Inc.| Credit card|       38.85|           480.31|            38.88| 0.006245966146865...|\n",
            "|       VeriFone Inc.|        Cash|         7.8|           480.31|             7.81| 0.002081988715621...|\n",
            "|       VeriFone Inc.| Credit card|       24.96|           480.31|             25.0| 0.00832795486248461%|\n",
            "+--------------------+------------+------------+-----------------+-----------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now when we have the data ready for submitting, I'll create a secure connection with Gmail’s SMTP server, using the SMTP_SSL() of smtplib to initiate a TLS-encrypted connection, and send email with attached CSV file. "
      ],
      "metadata": {
        "id": "Nqmj-gVT-eUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib, ssl\n",
        "\n",
        "import email, smtplib, ssl\n",
        "\n",
        "from email import encoders\n",
        "from email.mime.base import MIMEBase\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "port = 465  # For SSL\n",
        "smtp_server = \"smtp.gmail.com\"\n",
        "mail_subject = 'Test Email'\n",
        "sender_email = input('enter sender mail address:')  # Enter sender address\n",
        "receiver_email = input('enter receiver mail address:')  # Enter receiver address\n",
        "password = input(\"Type your password and press enter: \")\n",
        "\n",
        "subject = \"Avenga Academy Big Data Internship test task\"\n",
        "body = \"\"\"Test task submission by Kateryna Tatarchenko\"\"\"\n",
        "html = \"\"\"\\\n",
        "<html>\n",
        "  <body>\n",
        "    <p>Hi there! Hope you are doing well!<br>\n",
        "       Thank you for sending me this task, this was my first practice with Apache Spark (Python) and it was a bit challenging but really interesting!<br>\n",
        "       For this attemp, I've used spark through Google Colab (.ipunb), and most data manipulation were performed using Pandas.<br>\n",
        "       I've tried to keep the initial dataset without changes, as NUll values were allowed for all fields. However, there was a necessary replacement of 0 values by Null for Passengers Count,in order to perform correct Rate Calculations.\n",
        "      <br><br>\n",
        "       All the explanations of performed steps can be found in my Big Data Internship.ipynb file,\n",
        "       <a href=\"http://www.realpython.com\">link to Github</a> \n",
        "       <br>\n",
        "       Any feedback would be greatly appreaciated!\n",
        "\n",
        "       <br>\n",
        "       <br>\n",
        "       Have a great day ahead, and look forward to hearing from you!\n",
        "       <br>\n",
        "       Kind regards,<br>\n",
        "       Kate Tatarchenko\n",
        "    </p>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "message = MIMEMultipart()\n",
        "message[\"From\"] = sender_email\n",
        "message[\"To\"] = receiver_email\n",
        "message[\"Subject\"] = subject\n",
        "\n",
        "part1 = MIMEText(body, \"plain\")\n",
        "part2 = MIMEText(html, \"html\")\n",
        "\n",
        "message.attach(part1)\n",
        "message.attach(part2)\n",
        "\n",
        "with open(\"/content/reportDataTaxi.csv/reportDataTaxi.csv\", \"rb\") as attachment:\n",
        "    # Add file as application/octet-stream\n",
        "    # Email client can usually download this automatically as attachment\n",
        "    part = MIMEBase(\"application\", \"octet-stream\")\n",
        "    part.set_payload(attachment.read())\n",
        "\n",
        "# Encode file in ASCII characters to send by email    \n",
        "encoders.encode_base64(part)\n",
        "\n",
        "# Add header as key/value pair to attachment part\n",
        "part.add_header(\n",
        "    \"Content-Disposition\",\n",
        "    f\"attachment; filename= {'reportDataTaxi.csv'}\",\n",
        ")\n",
        "\n",
        "# Add attachment to message and convert message to string\n",
        "message.attach(part)\n",
        "text = message.as_string()\n",
        "\n",
        "context = ssl.create_default_context()\n",
        "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
        "    server.login(sender_email, password)\n",
        "    server.sendmail(sender_email, receiver_email, message.as_string())\n",
        "\n",
        "print(\"Message Sent!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zgto_KDN0h7",
        "outputId": "ea864a0a-e61b-4020-f156-d4355d25a3dd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter sender mail address:katetatarchenko@gmail.com\n",
            "enter receiver mail address:ktatarch.test@gmail.com\n",
            "Type your password and press enter: oeyscbxkaqxdqdan\n",
            "Message Sent!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "81Z1dtxId0kv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}